{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow Lite.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavorJordacevic/TensorFlow-Keras-Neural-Networks/blob/master/TensorFlow_Lite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enSkNL5VdA7A",
        "colab_type": "code",
        "outputId": "98fe7c28-6234-41a9-feea-ae2ef3ca1365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hoNaFvJc6AX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UXkmA14dcyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O cats_and_dogs_filtered.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU3tjOeBdeZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with zipfile.ZipFile(\"cats_and_dogs_filtered.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkokkV4Wdfpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = 'cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbju3dSadg6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNetV2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7NY8m_2dj3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = MobileNetV2(input_shape=(224, 224, 3),\n",
        "                                      include_top=False,\n",
        "                                      weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELSYFhG8dlFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Q5GrKWdn1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([base_model,\n",
        "                    GlobalAveragePooling2D(),\n",
        "                    Dense(1, activation='sigmoid')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC56Yh8KdoyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZPo0b-Cd0v1",
        "colab_type": "code",
        "outputId": "250c7450-10a7-40a7-9b2c-14dc56fbc78f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5fGc2qbdqmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      epochs=6,\n",
        "      validation_data=validation_generator,\n",
        "      verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdu0VUYadtBg",
        "colab_type": "code",
        "outputId": "1bc544a8-3a9f-4db5-b95b-3e07fdddcef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Converting a tf.Keras model to a TensorFlow Lite model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8861428"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju54F8vQfZ5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeHNS8sYjWFz",
        "colab_type": "code",
        "outputId": "cf85e47e-660e-401b-e212-02c33381ee1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Get input and output tensors.\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details= interpreter.get_output_details()\n",
        "\n",
        "print(\"== Input details ==\")\n",
        "print(\"shape:\", input_details[0]['shape'])\n",
        "print(\"type:\", input_details[0]['dtype'])\n",
        "print(\"\\n== Output details ==\")\n",
        "print(\"shape:\", output_details[0]['shape'])\n",
        "print(\"type:\", output_details[0]['dtype'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "== Input details ==\n",
            "shape: [  1 224 224   3]\n",
            "type: <class 'numpy.float32'>\n",
            "\n",
            "== Output details ==\n",
            "shape: [1 1]\n",
            "type: <class 'numpy.float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI4j4FZvn7mU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter.resize_tensor_input(input_details[0]['index'], (32, 224, 224, 3))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (32, 5))\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om51_XvYixfL",
        "colab_type": "code",
        "outputId": "bda42e23-9546-4927-ac8d-dbe7333712d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Get input and output tensors.\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details= interpreter.get_output_details()\n",
        "\n",
        "print(\"== Input details ==\")\n",
        "print(\"shape:\", input_details[0]['shape'])\n",
        "print(\"type:\", input_details[0]['dtype'])\n",
        "print(\"\\n== Output details ==\")\n",
        "print(\"shape:\", output_details[0]['shape'])\n",
        "print(\"type:\", output_details[0]['dtype'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "== Input details ==\n",
            "shape: [ 32 224 224   3]\n",
            "type: <class 'numpy.float32'>\n",
            "\n",
            "== Output details ==\n",
            "shape: [32  1]\n",
            "type: <class 'numpy.float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsKYGRMsiJKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_batch, label_batch = next(iter(validation_generator))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGQb8fGlh6ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], image_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDWYFvhFhnwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter.invoke()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkaeoayqhuRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "tf_results = model.predict(image_batch)\n",
        "\n",
        "for tf_result, tflite_result in zip(tf_results, tflite_results):\n",
        "  np.testing.assert_almost_equal(tf_result, tflite_result, decimal=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edwzCfn3rR7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_classes(tf_model, tf_lite_interpreter, x):\n",
        "  tf_lite_interpreter.set_tensor(input_details[0]['index'], x)\n",
        "  tf_lite_interpreter.invoke()\n",
        "  tflite_results = tf_lite_interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "  tf_results = model.predict_classes(x)\n",
        "\n",
        "  if tflite_results.shape[-1] > 1:\n",
        "    tflite_results = tflite_results.argmax(axis=-1)\n",
        "  else:\n",
        "    tflite_results = (tflite_results > 0.5).astype('int32')\n",
        "    \n",
        "  shape = (tf_results == tflite_results).shape\n",
        "\n",
        "  return (tf_results == tflite_results).reshape((shape[1], shape[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzOidehQr9Ts",
        "colab_type": "code",
        "outputId": "9daf72d2-1a22-4a84-b86b-940d802d05ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print((predict_classes(model, interpreter, image_batch)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "   True  True  True  True  True  True  True  True  True  True  True  True\n",
            "   True  True  True  True  True  True  True  True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrS2TJxz432S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1s4kp9S42gD",
        "colab_type": "code",
        "outputId": "efaf6a26-2c8e-433d-90cb-40d76136c49e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()\n",
        "open(\"converted_model.tflite\", \"wb\").write(tflite_quant_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2299040"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0IJXopK445E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UErJ0yKz4-8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get input and output tensors.\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details= interpreter.get_output_details()\n",
        "\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], (32, 224, 224, 3))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (32, 5))\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details= interpreter.get_output_details()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1N2P_pK5IAU",
        "colab_type": "code",
        "outputId": "5d8c5ba9-1099-4718-975e-ca4e28eccc23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print((predict_classes(model, interpreter, image_batch)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False  True  True  True  True  True False  True  True  True False  True\n",
            "  False False  True False  True  True  True  True  True False  True  True\n",
            "   True  True  True  True  True False  True False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nxJ9iZLh1gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_model(interpreter, validation_generator):\n",
        "  total_seen = 0\n",
        "  num_correct = 0\n",
        "\n",
        "  for img, label in validation_generator:\n",
        "    total_seen += img.shape[0]\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], img)\n",
        "    interpreter.invoke()\n",
        "    predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    if predictions.shape[-1] > 1:\n",
        "      predictions = predictions.argmax(axis=-1)\n",
        "    else:\n",
        "      predictions = (predictions > 0.5).astype('int32')\n",
        "\n",
        "    num_correct += np.sum(predictions == label.reshape(predictions.shape))\n",
        "\n",
        "    if total_seen % 10 == 0:\n",
        "      print(\"Accuracy after %i images: %f\" %\n",
        "            (total_seen, float(num_correct) / float(total_seen)))\n",
        "\n",
        "  return float(num_correct) / float(total_seen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPgfuyNVh9T0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(eval_model(interpreter, validation_generator))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK8uoicvFQDz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}